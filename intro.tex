\section{Introduction}\label{sec:intro}

Derivatives of regular expressions were introduced by Brzozowski \cite{Brzozowski64,OwensEtAl09}
to provide a very compact operational semantics for them, and to derive an algorithm for generating equivalent deterministic finite automata (DFA).

In a nutshell, derivatives can be defined by means of a labeled transition system between regular expressions, where labels are the alphabet symbols. Given a fixed symbol, at each step there is always a unique transition, therefore the system defines a deterministic automaton where the initial state is an initial regular expression $\re$, and all other states are regular expressions that are derivatives obtained from $\re$.

Such an automaton is provably equivalent to $\re$,
if the set of its final states is defined as the set of all the corresponding regular expressions which recognize the empty word.
The main issue with this approach is that the number of syntactically different derivatives of $\re$ can be unbounded, hence, to obtain an equivalent DFA, a finite quotient algebra of states modulo a suitable congruence has to be considered.

Inspired by Brzozowski's work, Antimirov \cite{Antimirov96} defined partial derivatives of regular expressions to define an algorithm that generates, from regular expressions, equivalent non-deterministic finite automata (NFA) with a limited number of states. The main breakthrough at the root of Antimirov's work is that the number of syntactically distinct partial derivatives of $\re$ is provably linear in the size of $\re$. Therefore, the same construction
proposed by Brzozowski can be used with syntactic equality without considering any weaker notion of congruence. However, the corresponding automaton is, in general non-deterministic, because
of the transition system defining partial derivatives: given a fixed symbol, at each step there can be zero or more transitions.

While Antimirov's work addresses the classical problem of word recognition in regular languages, here we are interested in runtime verification (RV)~\cite{LeuckerSchallhart09} of simple properties expressible with regular expressions.

RV is a dynamic technique used to check the trace of events generated during a single execution of the System Under Scrutiny (SUS). This is done with monitors automatically generated from specifications that describe the correct behavior of the SUS (suitably instrumented to produce the trace to be analyzed).

RV is complementary to both formal verification and testing: like formal methods, it is based on specification languages, although it is not exhaustive; like testing, it is scalable and suitable for real-world systems and complex properties. Differently from testing, RV can detect errors even in non-deterministic systems~\cite{HavelundRosu2004,SharmaEtAl2009,TowardsIoT17,SchiavioEtAl19}, and therefore represents a valuable complement to testing approaches~\cite{BesnardEtAl23}.

When properties to be dynamically verified can be defined with regular expressions, words are finite traces of monitorable events, which define the alphabet of the language, and the monitor is the DFA or NFA generated from the regular expression that recognizes the correct traces. However, in RV this approach may be unfeasible because of the intractable number of states of the generated automaton, even for NFAs.

This typically happens when the properties to be verified consist of sub-traces of mutually independent events, which are allowed to interleave during the execution of the system under scrutiny (SUS). Consider, for instance, the challenge of verifying that files are properly opened and closed, in a system able to handle multiple files independently. In such cases, extending regular expressions with the shuffle operator \cite{RML2021}
can significantly reduce the size of specifications and enhance clarity.
Moreover, by using partial derivatives, it becomes possible to avoid generating automata with an intractable number of states, and adopt, instead, a rewriting-based approach~\cite{RosuEtAl2005,RML2021}  to RV, where only a single partial derivative needs to be considered at each reduction step.

This raises the question of the space complexity of the largest partial derivative that can be generated from an initial regular expression. Indeed, while the total number of generated partial derivatives is known to be linear in the size of the initial regular expression, no results can be found in the literature regarding the size of the largest partial derivative.

In this paper, we investigate this problem with respect to two different metrics for regular expressions: their height and their total number of nodes when viewed as trees. In particular, we show that the height of the largest partial derivative can increase by at most one, while the number of nodes in the largest partial derivative is bounded by $n^2$, where $n$ is the number of nodes of the initial regular expression. Surprisingly, these results still hold when regular expressions are extended with shuffle.

To this aim, we propose a general proof strategy based on the definition of a function that returns the upper bounds of the increment after each single step which computes the partial derivative. In this way, an invariant can be established and extended to multiple rewriting steps, to be able to derive the expected space complexity results.  This proof strategy allows us to keep the same proof structure for all main results, and reuse parts of the proofs.

The paper is structured as follows: \Cref{sec:der} introduces the basic notion of derivatives of regular expressions. \Cref{sec:parDer} defines partial derivatives and proof the space complexity results ~\wrt~the height and the size of expressions.
\Cref{sec:shuffle} extends regular expressions with the shuffle operator, and show that the property proved in \cref{sec:parDer} still hold. Finally, \cref{sec:conclu} draws conclusions and directions for future work.
